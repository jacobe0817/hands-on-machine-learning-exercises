{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91e2f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d11be9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Train a LinearSVC on a linearly separable dataset. Then train an SVC and a SGDClassifier on the same dataset.\n",
    "#    See if you can get them to produce roughly the same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11262b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a linearly separable dataset\n",
    "# for this example, I will create a positive class (y = 1) centered around (1, 1)\n",
    "# and a negative class (y = 0) centered around (-1, -1)\n",
    "# each instance has random uniform error, on each axis, in the interval [-.5, .5)\n",
    "# each class has 100 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "431a3bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_positive = rng.random((100, 2)) + .5\n",
    "y_positive = np.full((100), 1)\n",
    "\n",
    "X_negative = -1 * rng.random((100, 2)) - .5\n",
    "y_negative = np.full((100), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "009519a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brief validation to show that there are no values in either column of X_positive that are negative\n",
    "# and there are no values in either column of X_negative that are positive\n",
    "# which guarantees that the dataset is linearly separable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d71471b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_positive[(X_positive[:, 0] < 0) | (X_positive[:, 1] < 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23aa7076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_negative[(X_negative[:, 0] > 0) | (X_negative[:, 1] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1664eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brief validation to show that X_positive and X_negative are centered around (1, 1) and (-1, -1), respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58e2524a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9700751 , 1.01766401])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_positive.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f012380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.99559213, -1.00285423])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_negative.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6df4e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glue the datasets together, then shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "593cc0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(X_positive, X_negative, axis=0)\n",
    "y = np.append(y_positive, y_negative, axis=0)\n",
    "\n",
    "X, y = shuffle(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dd48b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# briefly verify that training instances and labels were shuffled correctly\n",
    "# i.e. positive instances assigned to positive class and negative to negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cbee3a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 200), dtype=bool)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((np.apply_along_axis(sum, 1, X) >= 0).astype(int) == y)[False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "724ad02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normally I would create a test set and perform cross-validation but for this example I only care about\n",
    "# the similarity of the trained models rather than their performance and generalizability.\n",
    "# and besides, I know the exact logic of how the dataset was created because I created it,\n",
    "# which is the ultimate form of data snooping\n",
    "\n",
    "# so I will just train the models and see how similar I can make them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fb97a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61091041",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_scaled = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82624de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab539e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept : [0.00287337] \n",
      "weights : [[0.86910295 0.97667909]]\n"
     ]
    }
   ],
   "source": [
    "linear_svc = LinearSVC(loss='hinge')\n",
    "linear_svc.fit(X_scaled, y)\n",
    "print(f'intercept : {linear_svc.intercept_} \\nweights : {linear_svc.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98146086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept : [0.00287456] \n",
      "weights : [[0.86905621 0.97672094]]\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_scaled, y)\n",
    "print(f'intercept : {svc.intercept_} \\nweights : {svc.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67916b77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept : [0.00286905] \n",
      "weights : [[0.86912896 0.97665493]]\n"
     ]
    }
   ],
   "source": [
    "sgd_classifier = SGDClassifier(alpha=.005, tol=.0001, max_iter=1_000_000, n_iter_no_change=100_000, random_state=42)\n",
    "sgd_classifier.fit(X_scaled, y)\n",
    "print(f'intercept : {sgd_classifier.intercept_} \\nweights : {sgd_classifier.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ebd3cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "924e5899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Train an SVM classifier on the MNIST dataset. Since SVM classifiers are binary classifiers,\n",
    "#    you will need to use one-versus-the-rest to classify all 10 digits. You may want to tune the\n",
    "#    hyperparameters using small validation sets speed up the process. What accuracy can you reach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c816c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88422182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74391ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Train an SVM regressor on the California housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3147e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "921daf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84762d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3423f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to raw_data that assigns which decile of median_house_value that instance belongs to\n",
    "\n",
    "# note that this column is created to allow stratified sampling of the label in the creation of our test set.\n",
    "# because the deciles are calculated on the entire dataset (train and test),\n",
    "# it is important that we drop the column as soon as the train/test sets are formed.\n",
    "# this column should NOT be treated as an input feature because, having been calculated on the full dataset,\n",
    "# it is data snooping and will likely not generalize well to new data if used to train a model.\n",
    "# the column exists purely to ensure a wide variety of labels exists in both the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4df3b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "decile_1 = raw_data['median_house_value'].quantile(q=.1)\n",
    "decile_2 = raw_data['median_house_value'].quantile(q=.2)\n",
    "decile_3 = raw_data['median_house_value'].quantile(q=.3)\n",
    "decile_4 = raw_data['median_house_value'].quantile(q=.4)\n",
    "decile_5 = raw_data['median_house_value'].quantile(q=.5)\n",
    "decile_6 = raw_data['median_house_value'].quantile(q=.6)\n",
    "decile_7 = raw_data['median_house_value'].quantile(q=.7)\n",
    "decile_8 = raw_data['median_house_value'].quantile(q=.8)\n",
    "decile_9 = raw_data['median_house_value'].quantile(q=.9)\n",
    "\n",
    "decile_bins = [-np.inf, decile_1, decile_2, decile_3, decile_4, decile_5, decile_6, decile_7, decile_8, decile_9, np.inf]\n",
    "\n",
    "raw_data['decile'] = pd.cut(raw_data['median_house_value'], bins=decile_bins, labels=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1324f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test sets, drop decile column, and separate into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64c1fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_splitter = StratifiedShuffleSplit(n_splits=1, test_size=.2, random_state=42)\n",
    "train_test_split = stratified_splitter.split(raw_data, raw_data['decile'])\n",
    "\n",
    "train_set = None\n",
    "test_set = None\n",
    "\n",
    "for train_indices, test_indices in train_test_split:\n",
    "    train_set = raw_data.loc[train_indices]\n",
    "    test_set = raw_data.loc[test_indices]\n",
    "\n",
    "train_labels = train_set['median_house_value'].copy()\n",
    "test_labels = train_set['median_house_value'].copy()\n",
    "\n",
    "train_features = train_set.drop(columns=['median_house_value', 'decile'])\n",
    "test_features = test_set.drop(columns=['median_house_value', 'decile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49e3b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables for column names and identify indices for columns used in added numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d96b38b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_string = 'total_rooms'\n",
    "bedrooms_string = 'total_bedrooms'\n",
    "population_string = 'population'\n",
    "households_string = 'households'\n",
    "ocean_proximity_string = 'ocean_proximity'\n",
    "\n",
    "train_features_column_names = list(train_features.columns)\n",
    "\n",
    "rooms_index = train_features_column_names.index(rooms_string)\n",
    "bedrooms_index = train_features_column_names.index(bedrooms_string)\n",
    "population_index = train_features_column_names.index(population_string)\n",
    "households_index = train_features_column_names.index(households_string)\n",
    "\n",
    "bpr_string = 'bedrooms_per_room'\n",
    "rph_string = 'rooms_per_household'\n",
    "pph_string = 'population_per_household'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec5e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a transformer that adds the extra numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56da4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericalFeatureAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, numerical_features, add_bedrooms_per_room=False, add_rooms_per_household=False, add_population_per_household=False):\n",
    "        self.numerical_features = numerical_features\n",
    "        \n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "        self.add_rooms_per_household = add_rooms_per_household\n",
    "        self.add_population_per_household = add_population_per_household\n",
    "        \n",
    "        possible_features = (bpr_string, rph_string, pph_string)\n",
    "        parameter_settings = (self.add_bedrooms_per_room, self.add_rooms_per_household, self.add_population_per_household)\n",
    "\n",
    "        self.possible_features_and_parameter_settings = list(zip(possible_features, parameter_settings))\n",
    "        \n",
    "        self.added_features = []\n",
    "        \n",
    "        for possible_feature, parameter_setting in self.possible_features_and_parameter_settings:\n",
    "            if parameter_setting:\n",
    "                self.added_features.append(possible_feature)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        new_columns = None\n",
    "        \n",
    "        for possible_feature, parameter_setting in self.possible_features_and_parameter_settings:\n",
    "            new_column = None\n",
    "            if parameter_setting:\n",
    "                if possible_feature == bpr_string:\n",
    "                    new_column = X[:, bedrooms_index] / X[:, rooms_index]\n",
    "                elif possible_feature == rph_string:\n",
    "                    new_column = X[:, rooms_index] / X[:, households_index]\n",
    "                elif possible_feature == pph_string:\n",
    "                    new_column = X[:, population_index] / X[:, households_index]\n",
    "                if new_columns is None:\n",
    "                    new_columns = new_column\n",
    "                else:\n",
    "                    new_columns = np.c_[new_columns, new_column]\n",
    "        \n",
    "        if new_columns is None:\n",
    "            return X\n",
    "        \n",
    "        return np.c_[X, new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d2e39bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column transformer that performs data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e02d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, numerical_features, categorical_features, add_bpr=False, add_rph=False, add_pph=False):\n",
    "        self.add_bpr = add_bpr\n",
    "        self.add_rph = add_rph\n",
    "        self.add_pph = add_pph\n",
    "        \n",
    "        self.numerical_features = numerical_features        \n",
    "        self.categorical_features = categorical_features\n",
    "        self.numerical_pipeline = Pipeline([('imputer', SimpleImputer(strategy='median')),\n",
    "                                           ('feature_adder', NumericalFeatureAdder(self.numerical_features, add_bedrooms_per_room=self.add_bpr, add_rooms_per_household=self.add_rph, add_population_per_household=self.add_pph)),\n",
    "                                           ('scaler', StandardScaler())])\n",
    "        self.column_transformer = ColumnTransformer([('numerical', self.numerical_pipeline, self.numerical_features)\n",
    "                                                       , ('categorical', OneHotEncoder(handle_unknown='ignore'), self.categorical_features)])\n",
    "        self.added_numerical_features = self.numerical_pipeline.named_steps['feature_adder'].added_features\n",
    "        return\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.column_transformer.fit(X)\n",
    "        one_hot_encoder = self.column_transformer.named_transformers_['categorical']\n",
    "        self.features = self.numerical_features + self.added_numerical_features + list(np.concatenate(one_hot_encoder.categories_))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.column_transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25f145df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude',\n",
       " 'latitude',\n",
       " 'housing_median_age',\n",
       " 'total_rooms',\n",
       " 'total_bedrooms',\n",
       " 'population',\n",
       " 'households',\n",
       " 'median_income',\n",
       " 'bedrooms_per_room',\n",
       " '<1H OCEAN',\n",
       " 'INLAND',\n",
       " 'ISLAND',\n",
       " 'NEAR BAY',\n",
       " 'NEAR OCEAN']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = [ocean_proximity_string]\n",
    "numerical_features = list(train_features.drop(columns=categorical_features))\n",
    "\n",
    "data_preparer = DataPreparer(numerical_features, categorical_features, add_bpr=True)\n",
    "prepped_train_features = data_preparer.fit_transform(train_features)\n",
    "\n",
    "data_preparer.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c88e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brief validation of data preparer on first row of shuffled training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "700abd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "529ff99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 14)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepped_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dda0743",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude             -116.5\n",
       "latitude               33.82\n",
       "housing_median_age      16.0\n",
       "total_rooms            343.0\n",
       "total_bedrooms          85.0\n",
       "population              29.0\n",
       "households              14.0\n",
       "median_income         2.1042\n",
       "ocean_proximity       INLAND\n",
       "Name: 12344, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e25356c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.53652021, -0.8524502 , -1.00209463, -1.04711441, -1.0773835 ,\n",
       "       -1.25320775, -1.26619991, -0.92674015,  0.54898116,  0.        ,\n",
       "        1.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepped_train_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f695160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5364736790267735"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_features.iloc[0, 0] - train_features['longitude'].mean())/train_features['longitude'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6aeb9666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point, you could create a data preparation and prediction pipeline\n",
    "# if you want to perform a grid/random search including parameters of data preparation.\n",
    "# however, I am just going to use the default DataPreparer (i.e. no added features), so this is unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e966830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a coarse grid/random search with cv=5 to find the best hyperparameter values\n",
    "\n",
    "# make sure to return train scores so you can compare train and validation scores.\n",
    "# if there is a large discrepancy between train and validation scores, you are overfitting and should regularize\n",
    "\n",
    "# the GridSearchCV calls were taking a long time so instead of combining the parameter grids into one list,\n",
    "# I separated them by kernel (linear, poly, etc.). For future reference, ASDF is the best kernel\n",
    "# so don't bother running the other cells unless you want to wait a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b671f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_C_list = [.01, 1, 100]\n",
    "coarse_epsilon_list = [.001, .1, 10]\n",
    "coarse_coef0_list = [0, 1, 10]\n",
    "\n",
    "coarse_linear_parameter_grid = {'kernel' : ['linear'], 'C' : coarse_C_list, 'epsilon' : coarse_epsilon_list}\n",
    "coarse_poly_parameter_grid = {'kernel' : ['poly'], 'degree' : [2, 3], 'gamma' : ['scale', 'auto'], 'coef0' : coarse_coef0_list, 'C' : coarse_C_list, 'epsilon' : coarse_epsilon_list}\n",
    "coarse_rbf_parameter_grid = {'kernel' : ['rbf'], 'gamma' : ['scale', 'auto'], 'C' : coarse_C_list, 'epsilon' : coarse_epsilon_list}\n",
    "coarse_sigmoid_parameter_grid = coarse_poly_parameter_grid = {'kernel' : ['sigmoid'], 'gamma' : ['scale', 'auto'], 'coef0' : coarse_coef0_list, 'C' : coarse_C_list, 'epsilon' : coarse_epsilon_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660bf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f6755a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVR(),\n",
       "             param_grid={'C': [0.01, 1, 100], 'epsilon': [0.001, 0.1, 10],\n",
       "                         'kernel': ['linear']},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_linear_grid_search = GridSearchCV(SVR(), coarse_linear_parameter_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "coarse_linear_grid_search.fit(prepped_train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74457314",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\18/ipykernel_8336/340693017.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcoarse_linear_grid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.sqrt(-coarse_linear_grid_search.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a511b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVR(),\n",
       "             param_grid={'C': [0.01, 1, 100], 'coef0': [0, 1, 10],\n",
       "                         'epsilon': [0.001, 0.1, 10],\n",
       "                         'gamma': ['scale', 'auto'], 'kernel': ['sigmoid']},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_poly_grid_search = GridSearchCV(SVR(), coarse_poly_parameter_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "coarse_poly_grid_search.fit(prepped_train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d310e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0822c3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_rbf_grid_search = GridSearchCV(SVR(), coarse_rbf_parameter_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "coarse_rbf_grid_search.fit(prepped_train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b79bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3078ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_linear_grid_search = GridSearchCV(SVR(), coarse_linear_parameter_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "coarse_linear_grid_search.fit(prepped_train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb3ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a more refined grid/random search centered on the best hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b01168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f68c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select model hyperparameters and train on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a278b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3387ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f21b88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
